{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, pipeline  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "from datasets import Dataset \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import evaluate \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d98218abc43447d81a89f635b9ee24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "main_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "models_dir = os.path.abspath(os.path.join(main_dir, 'models')) \n",
    "ft_model = os.path.abspath(os.path.join(models_dir, 'finetuned_model'))\n",
    "output_dir = os.path.abspath(os.path.join(models_dir, 'finetuned-model-movie-review-sentiment-analysis'))\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(ft_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(ft_model)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data_preprocessed.csv')\n",
    "dataset = Dataset.from_pandas(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9cdb337c9d459f8188a1819a8f6bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "tokenized_ds = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_ds = tokenized_ds.train_test_split(test_size=0.2)\n",
    "\n",
    "small_train = tokenized_ds['train'].shuffle(seed=13).select(range(200)) \n",
    "small_test = tokenized_ds['test'].shuffle(seed=13).select(range(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    save_strategy='epoch',\n",
    "    eval_strategy='epoch',\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=1.2090707659718472e-05, # best parameters from optimization \n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_ratio=0.09356655990374085,\n",
    "    fp16=True,\n",
    "    optim=\"adamw_8bit\",\n",
    "    gradient_accumulation_steps=4,\n",
    "    push_to_hub=True,\n",
    "    hub_strategy='end',\n",
    "    load_best_model_at_end=True,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred \n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # Evaluation metrics for classification\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=None)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    auc = roc_auc_score(labels, logits[:, 1])\n",
    "\n",
    "    return {\n",
    "       \"accuracy\": float(acc),\n",
    "        \"f1\": f1.tolist(),       \n",
    "        \"precision\": precision.tolist(),\n",
    "        \"recall\": recall.tolist(),\n",
    "        \"auc\": auc.tolist()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train,\n",
    "    eval_dataset=small_test,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 10:25, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.296286</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>[0.9281767955801105, 0.9406392694063926]</td>\n",
       "      <td>[0.9545454545454546, 0.9196428571428571]</td>\n",
       "      <td>[0.9032258064516129, 0.9626168224299065]</td>\n",
       "      <td>0.988443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.233832</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>[0.946236559139785, 0.9532710280373832]</td>\n",
       "      <td>[0.946236559139785, 0.9532710280373832]</td>\n",
       "      <td>[0.946236559139785, 0.9532710280373832]</td>\n",
       "      <td>0.988544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.264143</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>[0.9347826086956522, 0.9444444444444444]</td>\n",
       "      <td>[0.945054945054945, 0.9357798165137615]</td>\n",
       "      <td>[0.9247311827956989, 0.9532710280373832]</td>\n",
       "      <td>0.987840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262721</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>[0.9347826086956522, 0.9444444444444444]</td>\n",
       "      <td>[0.945054945054945, 0.9357798165137615]</td>\n",
       "      <td>[0.9247311827956989, 0.9532710280373832]</td>\n",
       "      <td>0.987790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samhk\\anaconda3\\Lib\\site-packages\\transformers\\configuration_utils.py:407: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 512}\n",
      "  warnings.warn(\n",
      "C:\\Users\\samhk\\anaconda3\\Lib\\site-packages\\transformers\\configuration_utils.py:407: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 512}\n",
      "  warnings.warn(\n",
      "C:\\Users\\samhk\\anaconda3\\Lib\\site-packages\\transformers\\configuration_utils.py:407: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 512}\n",
      "  warnings.warn(\n",
      "C:\\Users\\samhk\\anaconda3\\Lib\\site-packages\\transformers\\configuration_utils.py:407: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 512}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=52, training_loss=0.1440546329204853, metrics={'train_runtime': 628.8041, 'train_samples_per_second': 1.272, 'train_steps_per_second': 0.083, 'total_flos': 228072041808768.0, 'train_loss': 0.1440546329204853, 'epoch': 4.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.23383209109306335,\n",
       " 'eval_accuracy': 0.95,\n",
       " 'eval_f1': [0.946236559139785, 0.9532710280373832],\n",
       " 'eval_precision': [0.946236559139785, 0.9532710280373832],\n",
       " 'eval_recall': [0.946236559139785, 0.9532710280373832],\n",
       " 'eval_auc': 0.9885438649381971,\n",
       " 'eval_runtime': 30.4907,\n",
       " 'eval_samples_per_second': 6.559,\n",
       " 'eval_steps_per_second': 1.64,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samhk\\anaconda3\\Lib\\site-packages\\transformers\\configuration_utils.py:407: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 512}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79be806324bf40b8b88c8f0d44c2595a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ab0303e98d41e39fcb39bc25a96202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5773bb10d51a4b0fb0800f2c468d05ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/738M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/lemonsterpie/finetuned-model-movie-review-sentiment-analysis/commit/859997d4e30e676292e8d66acae2bd5c679fc9ab', commit_message='End of training', commit_description='', oid='859997d4e30e676292e8d66acae2bd5c679fc9ab', pr_url=None, repo_url=RepoUrl('https://huggingface.co/lemonsterpie/finetuned-model-movie-review-sentiment-analysis', endpoint='https://huggingface.co', repo_type='model', repo_id='lemonsterpie/finetuned-model-movie-review-sentiment-analysis'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing my model \n",
    "\n",
    "tester = pd.read_csv('../data/tester_data.csv') # Preprocessed data from step 1 \n",
    "test1 = tester.head(10).copy() \n",
    "test1_list = test1['preprocessed_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4ec2446fff488bba57a625978b0b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samhk\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\samhk\\.cache\\huggingface\\hub\\models--lemonsterpie--finetuned-model-movie-review-sentiment-analysis. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc16c54936ad44efa5241b3ec66dedb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/738M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03dfde7ce2545368a16d0325bca75de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f5a3a2ae384d83bece8720a3ee663a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2970237f9bee471a8764f979c4110a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "my_model = pipeline('text-classification', model='lemonsterpie/finetuned-model-movie-review-sentiment-analysis')\n",
    "test1_predictions = my_model(test1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.loc[:, \"predicted_label\"] = [p[\"label\"] for p in test1_predictions]\n",
    "test1.loc[:, \"confidence_score\"] = [p[\"score\"] for p in test1_predictions]\n",
    "test1['predicted_label'] = test1['predicted_label'].map({'POS': 1, 'NEG': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>confidence_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love sci-fi and am willing to put up with a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>i love sci fi and am willing to put up with a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Worth the entertainment value of a rental, esp...</td>\n",
       "      <td>0</td>\n",
       "      <td>worth the entertainment value of a rental  esp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its a totally average film with a few semi-alr...</td>\n",
       "      <td>0</td>\n",
       "      <td>its a totally average film with a few semi alr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STAR RATING: ***** Saturday Night **** Friday ...</td>\n",
       "      <td>0</td>\n",
       "      <td>star rating        saturday night      friday ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First off let me say, If you haven't enjoyed a...</td>\n",
       "      <td>0</td>\n",
       "      <td>first off let me say  if you havent enjoyed a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I had high hopes for this one until they chang...</td>\n",
       "      <td>0</td>\n",
       "      <td>i had high hopes for this one until they chang...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Isaac Florentine has made some of the best wes...</td>\n",
       "      <td>0</td>\n",
       "      <td>isaac florentine has made some of the best wes...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>It actually pains me to say it, but this movie...</td>\n",
       "      <td>0</td>\n",
       "      <td>it actually pains me to say it  but this movie...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Technically I'am a Van Damme Fan, or I was. th...</td>\n",
       "      <td>0</td>\n",
       "      <td>technically iam a van damme fan  or i was  thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Honestly awful film, bad editing, awful lighti...</td>\n",
       "      <td>0</td>\n",
       "      <td>honestly awful film  bad editing  awful lighti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  I love sci-fi and am willing to put up with a ...      0   \n",
       "1  Worth the entertainment value of a rental, esp...      0   \n",
       "2  its a totally average film with a few semi-alr...      0   \n",
       "3  STAR RATING: ***** Saturday Night **** Friday ...      0   \n",
       "4  First off let me say, If you haven't enjoyed a...      0   \n",
       "5  I had high hopes for this one until they chang...      0   \n",
       "6  Isaac Florentine has made some of the best wes...      0   \n",
       "7  It actually pains me to say it, but this movie...      0   \n",
       "8  Technically I'am a Van Damme Fan, or I was. th...      0   \n",
       "9  Honestly awful film, bad editing, awful lighti...      0   \n",
       "\n",
       "                                   preprocessed_text  predicted_label  \\\n",
       "0  i love sci fi and am willing to put up with a ...                0   \n",
       "1  worth the entertainment value of a rental  esp...                0   \n",
       "2  its a totally average film with a few semi alr...                0   \n",
       "3  star rating        saturday night      friday ...                0   \n",
       "4  first off let me say  if you havent enjoyed a ...                1   \n",
       "5  i had high hopes for this one until they chang...                0   \n",
       "6  isaac florentine has made some of the best wes...                0   \n",
       "7  it actually pains me to say it  but this movie...                0   \n",
       "8  technically iam a van damme fan  or i was  thi...                0   \n",
       "9  honestly awful film  bad editing  awful lighti...                0   \n",
       "\n",
       "   confidence_score  \n",
       "0          0.998382  \n",
       "1          0.998148  \n",
       "2          0.998320  \n",
       "3          0.998932  \n",
       "4          0.997490  \n",
       "5          0.998872  \n",
       "6          0.997942  \n",
       "7          0.998562  \n",
       "8          0.998766  \n",
       "9          0.998717  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first off let me say  if you havent enjoyed a van damme movie since bloodsport  you probably will not like this movie  most of these movies may not have the best plots or best actors but i enjoy these kinds of movies for what they are  this movie is much better than any of the movies the other action guys  segal and dolph  have thought about putting out the past few years  van damme is good in the movie  the movie is only worth watching to van damme fans  it is not as good as wake of death  which i highly recommend to anyone of likes van damme  or in hell but  in my opinion its worth watching  it has the same type of feel to it as nowhere to run  good fun stuff '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the mismatched prediction \n",
    "\n",
    "mismatch1 = test1[test1['label'] != test1['predicted_label']]\n",
    "mismatch1.iloc[0,2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing another batch \n",
    "\n",
    "test2 = tester.tail(10).copy()\n",
    "test2_list = test2['preprocessed_text'].tolist()\n",
    "test2_predictions = my_model(test2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.loc[:, \"predicted_label\"] = [p[\"label\"] for p in test2_predictions]\n",
    "test2.loc[:, \"confidence_score\"] = [p[\"score\"] for p in test2_predictions]\n",
    "test2['predicted_label'] = test2['predicted_label'].map({'POS': 1, 'NEG': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>confidence_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>I first saw this on Demand. Or on TV. I'm not ...</td>\n",
       "      <td>1</td>\n",
       "      <td>i first saw this on demand  or on tv  im not r...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>In the veins of Jeepers Creepers and The Texas...</td>\n",
       "      <td>1</td>\n",
       "      <td>in the veins of jeepers creepers and the texas...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>Great horror comedy from Michael Davis.Iwas la...</td>\n",
       "      <td>1</td>\n",
       "      <td>great horror comedy from michael davis iwas la...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>Two city guys are driving through Hicksville U...</td>\n",
       "      <td>1</td>\n",
       "      <td>two city guys are driving through hicksville u...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>This is a surprisingly great low budget Horror...</td>\n",
       "      <td>1</td>\n",
       "      <td>this is a surprisingly great low budget horror...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>Just got around to seeing Monster Man yesterda...</td>\n",
       "      <td>1</td>\n",
       "      <td>just got around to seeing monster man yesterda...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>I got this as part of a competition prize. I w...</td>\n",
       "      <td>1</td>\n",
       "      <td>i got this as part of a competition prize  i w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>I got Monster Man in a box set of three films ...</td>\n",
       "      <td>1</td>\n",
       "      <td>i got monster man in a box set of three films ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>Five minutes in, i started to feel how naff th...</td>\n",
       "      <td>1</td>\n",
       "      <td>five minutes in  i started to feel how naff th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>I caught this movie on the Sci-Fi channel rece...</td>\n",
       "      <td>1</td>\n",
       "      <td>i caught this movie on the sci fi channel rece...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "24990  I first saw this on Demand. Or on TV. I'm not ...      1   \n",
       "24991  In the veins of Jeepers Creepers and The Texas...      1   \n",
       "24992  Great horror comedy from Michael Davis.Iwas la...      1   \n",
       "24993  Two city guys are driving through Hicksville U...      1   \n",
       "24994  This is a surprisingly great low budget Horror...      1   \n",
       "24995  Just got around to seeing Monster Man yesterda...      1   \n",
       "24996  I got this as part of a competition prize. I w...      1   \n",
       "24997  I got Monster Man in a box set of three films ...      1   \n",
       "24998  Five minutes in, i started to feel how naff th...      1   \n",
       "24999  I caught this movie on the Sci-Fi channel rece...      1   \n",
       "\n",
       "                                       preprocessed_text  predicted_label  \\\n",
       "24990  i first saw this on demand  or on tv  im not r...                1   \n",
       "24991  in the veins of jeepers creepers and the texas...                1   \n",
       "24992  great horror comedy from michael davis iwas la...                1   \n",
       "24993  two city guys are driving through hicksville u...                1   \n",
       "24994  this is a surprisingly great low budget horror...                1   \n",
       "24995  just got around to seeing monster man yesterda...                1   \n",
       "24996  i got this as part of a competition prize  i w...                1   \n",
       "24997  i got monster man in a box set of three films ...                1   \n",
       "24998  five minutes in  i started to feel how naff th...                1   \n",
       "24999  i caught this movie on the sci fi channel rece...                1   \n",
       "\n",
       "       confidence_score  \n",
       "24990          0.998639  \n",
       "24991          0.997644  \n",
       "24992          0.998805  \n",
       "24993          0.995993  \n",
       "24994          0.999247  \n",
       "24995          0.998298  \n",
       "24996          0.997778  \n",
       "24997          0.998848  \n",
       "24998          0.997703  \n",
       "24999          0.997998  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No mismatches for test 2! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
